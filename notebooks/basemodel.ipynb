{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "emb = nn.Embedding(num_embeddings=2000, embedding_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([[1,2], [3,3]], dtype=torch.int32).int()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2070,  0.0868,  0.2793,  ...,  0.1696,  0.0606,  1.5118],\n",
       "        [ 0.7185,  1.7097, -0.3803,  ..., -1.4022,  1.5750, -2.4132],\n",
       "        [-0.6919, -0.4048,  0.5235,  ...,  0.2458, -1.1409, -1.1572],\n",
       "        ...,\n",
       "        [-0.0375,  1.1583, -0.4485,  ...,  0.6072,  0.5381, -0.7682],\n",
       "        [ 1.0264,  0.3425,  0.2802,  ...,  1.2693, -0.2440,  1.7639],\n",
       "        [-0.6822, -0.5398, -0.6730,  ..., -0.6008,  0.4224, -0.8169]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7185,  1.7097, -0.3803, -0.9844, -2.1273,  1.0098, -1.0400,  0.6035,\n",
       "          0.5341, -1.3867, -0.1350, -0.8774,  1.0256, -1.4022,  1.5750, -2.4132],\n",
       "        [ 0.5814, -0.5005, -1.0239, -0.2890,  0.1840, -0.3994,  0.0467,  0.2294,\n",
       "         -1.4097,  0.2304, -0.7351, -0.2720, -0.7556,  0.0195,  1.5493, -1.1773]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(labels[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\t\"\"\"station should be in axis0 (index), timestamp should be axis1 (columns)\n",
    "\n",
    "\tArgs:\n",
    "\t\tsequences (_type_): _description_\n",
    "\t\tn_steps_in (_type_): _description_\n",
    "\t\tn_steps_out (_type_): _description_\n",
    "\n",
    "\tReturns:\n",
    "\t\t_type_: _description_\n",
    "\t\"\"\"\n",
    "\tsize = sequences.shape[1]\n",
    "\txs = np.empty((0,n_steps_in))\n",
    "\tys = np.empty((0,n_steps_out))\n",
    "\n",
    "\tfor idx in tqdm(range(1008-n_steps_in, size - (n_steps_in + n_steps_out))):\n",
    "\t\tx = sequences[:,idx:idx+n_steps_in]\n",
    "\t\txs = np.vstack([xs, x])\n",
    "\t\ty = sequences[:, idx+n_steps_in:idx+n_steps_in+n_steps_out]\n",
    "\t\tys = np.vstack([ys, y])\n",
    "\treturn xs, ys\n",
    "\n",
    "\n",
    "def station_features(station_array, station_df, n_windows):\n",
    "\tdf = pd.DataFrame(data=station_array, columns=['station_name']).merge(station_df[['station_name', 'dcode']], how='left', on='station_name')\n",
    "\tname_encoder = {name:idx for idx, name in enumerate(df.station_name.unique())}\n",
    "\tdcode_encoder = {name:idx for idx, name in enumerate(df.dcode.unique())}\n",
    "\n",
    "\tdf.station_name = df.station_name.map(name_encoder)\n",
    "\tdf.dcode = df.dcode.map(dcode_encoder)\n",
    "\n",
    "\treturn np.tile(df.values, (n_windows,1))\n",
    "\n",
    "\n",
    "def time_features(time_idx, n_steps_in, n_steps_out, n_stations):\n",
    "\tdf = pd.DataFrame(data=pd.to_datetime(time_idx), columns=['time'])\t\n",
    "\n",
    "\t# df['seconds'] = df['time'].dt.hour.multiply(3600) + df['time'].dt.minute.multiply(60)\n",
    "\t# seconds_in_day = 24*60*60\n",
    "\t# df['sin_time'] = df['seconds'].divide(seconds_in_day).multiply(2*np.pi).map(np.sin)\n",
    "\t# df['cos_time'] = df['seconds'].divide(seconds_in_day).multiply(2*np.pi).map(np.cos)\n",
    "\tdf['t_index']  = df['time'].dt.hour.multiply(60).add(df['time'].dt.minute).floordiv(30)\n",
    "\tdf['dow'] = df['time'].dt.dayofweek\n",
    "\tdf['weekend'] = df.dow.isin([5,6]).astype(np.int64)\n",
    "\tdel df['time']\n",
    "\n",
    "\tts = np.empty((0,n_steps_out,3))\n",
    "\tfor idx in tqdm(range(1008-n_steps_in, len(time_idx) - (n_steps_in + n_steps_out))):\n",
    "\t\tt = df.values[np.newaxis, idx+n_steps_in:idx+n_steps_in+n_steps_out, :]\n",
    "\t\tts = np.vstack([ts, t])\n",
    "\n",
    "\treturn np.repeat(ts, n_stations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history = pd.read_csv('../data/input_table/history_by_station.csv', parse_dates=['time'])\n",
    "station = pd.read_csv('../data/input_table/station_info.csv')\n",
    "\n",
    "\n",
    "data = history.set_index('time').T.reset_index().rename(columns={'index':'station_name'})\n",
    "data = data[data.station_name.isin(station.station_name)].set_index('station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>time</th>\n",
       "      <th>2021-07-01 00:00:00</th>\n",
       "      <th>2021-07-01 00:30:00</th>\n",
       "      <th>2021-07-01 01:00:00</th>\n",
       "      <th>2021-07-01 01:30:00</th>\n",
       "      <th>2021-07-01 02:00:00</th>\n",
       "      <th>2021-07-01 02:30:00</th>\n",
       "      <th>2021-07-01 03:00:00</th>\n",
       "      <th>2021-07-01 03:30:00</th>\n",
       "      <th>2021-07-01 04:00:00</th>\n",
       "      <th>2021-07-01 04:30:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2021-09-30 19:00:00</th>\n",
       "      <th>2021-09-30 19:30:00</th>\n",
       "      <th>2021-09-30 20:00:00</th>\n",
       "      <th>2021-09-30 20:30:00</th>\n",
       "      <th>2021-09-30 21:00:00</th>\n",
       "      <th>2021-09-30 21:30:00</th>\n",
       "      <th>2021-09-30 22:00:00</th>\n",
       "      <th>2021-09-30 22:30:00</th>\n",
       "      <th>2021-09-30 23:00:00</th>\n",
       "      <th>2021-09-30 23:30:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(주)플러스 전용 전기버스 충전소</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.786111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.752778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2생활권 환승주차장1(A)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.772222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2호선 양산역</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGV 신대점</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC아이파크 아파트</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "time                2021-07-01 00:00:00  2021-07-01 00:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-07-01 01:00:00  2021-07-01 01:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-07-01 02:00:00  2021-07-01 02:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-07-01 03:00:00  2021-07-01 03:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-07-01 04:00:00  2021-07-01 04:30:00  ...  \\\n",
       "station_name                                                  ...   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0  ...   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0  ...   \n",
       "2호선 양산역                             1.0                  1.0  ...   \n",
       "CGV 신대점                             1.0                  1.0  ...   \n",
       "DMC아이파크 아파트                         1.0                  1.0  ...   \n",
       "\n",
       "time                2021-09-30 19:00:00  2021-09-30 19:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  0.5             0.786111   \n",
       "2생활권 환승주차장1(A)                      1.0             1.000000   \n",
       "2호선 양산역                             1.0             1.000000   \n",
       "CGV 신대점                             1.0             1.000000   \n",
       "DMC아이파크 아파트                         1.0             1.000000   \n",
       "\n",
       "time                2021-09-30 20:00:00  2021-09-30 20:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-09-30 21:00:00  2021-09-30 21:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소                  1.0                  1.0   \n",
       "2생활권 환승주차장1(A)                      1.0                  1.0   \n",
       "2호선 양산역                             1.0                  1.0   \n",
       "CGV 신대점                             1.0                  1.0   \n",
       "DMC아이파크 아파트                         1.0                  1.0   \n",
       "\n",
       "time                2021-09-30 22:00:00  2021-09-30 22:30:00  \\\n",
       "station_name                                                   \n",
       "(주)플러스 전용 전기버스 충전소             0.541667                  0.0   \n",
       "2생활권 환승주차장1(A)                 1.000000                  1.0   \n",
       "2호선 양산역                        1.000000                  1.0   \n",
       "CGV 신대점                        1.000000                  1.0   \n",
       "DMC아이파크 아파트                    1.000000                  1.0   \n",
       "\n",
       "time                2021-09-30 23:00:00  2021-09-30 23:30:00  \n",
       "station_name                                                  \n",
       "(주)플러스 전용 전기버스 충전소             0.075000             0.752778  \n",
       "2생활권 환승주차장1(A)                 0.327778             0.772222  \n",
       "2호선 양산역                        1.000000             1.000000  \n",
       "CGV 신대점                        1.000000             1.000000  \n",
       "DMC아이파크 아파트                    1.000000             1.000000  \n",
       "\n",
       "[5 rows x 4416 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_name\n",
       "LH강원본부           False\n",
       "LH경기지사           False\n",
       "LH경남본부           False\n",
       "LH인천본부           False\n",
       "가락2동 주민센터         True\n",
       "                 ...  \n",
       "회차지(월드컵경기장)       True\n",
       "회차지(인라인스케이트장)    False\n",
       "회천1동주민센터         False\n",
       "효자종합시장공영주차장      False\n",
       "후평1동행정복지센터       False\n",
       "Length: 250, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean(axis=1).le(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.mean(axis=1).le(0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['가락2동 주민센터', '강남구청 공영주차장', '강동송파지사', '강변테크노마트 주차장', '거여2동 주민센터', '계양구청',\n",
       "       '관악동작 견인차량 보관소', '교1동주민센터', '구로구청 주차장', '금천구청 지상 주차장', '남인천지사',\n",
       "       '녹산산단 공영주차장', '대전역사박물관', '대평동 BRT전기버스 차고지', '도봉구청', '뚝도충전소',\n",
       "       '매월동 전기버스 충전소', '빛가람 주민센터', '빛가람동 공용차고지', '상인대성스카이렉스 아파트', '오천읍사무소',\n",
       "       '용산전자상가1 공영주차장', '은평평화공원 공영주차장', '을숙도 공영주차장', '인천업사이클 에코센터', '장등공용차고지',\n",
       "       '전기공사협회 주차장', '중부산지사', '지식산업센터(동일테크노타운8차)', '첨단공용차고지', '한밭종합운동장 주차장',\n",
       "       '한일병원', '회차지(대성공영주차장)', '회차지(완산체련공원)', '회차지(월드컵경기장)'],\n",
       "      dtype='object', name='station_name')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 42 is out of bounds for axis 0 with size 35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40657/889155817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloordiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42 is out of bounds for axis 0 with size 35"
     ]
    }
   ],
   "source": [
    "name = data.index[42]\n",
    "print(name)\n",
    "\n",
    "df = data.T[[name]].reset_index().copy()\n",
    "df['step'] = df.time.dt.hour.multiply(60).add(df['time'].dt.minute).floordiv(30)\n",
    "df.groupby('step')[name].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tsize = sequences.shape[1]\n",
    "\ths = np.empty((0,3))\n",
    "\n",
    "\tfor idx in tqdm(range(1008-n_steps_in, size - (n_steps_in + n_steps_out))):\n",
    "\t\th = sequences[:, [idx+n_steps_in-336, idx+n_steps_in-672, idx+n_steps_in-1008]]\n",
    "\t\ths = np.vstack([hs, h])\n",
    "\treturn hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_name    1899\n",
       "dcode             18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3402/3402 [00:00<00:00, 47337.76it/s]\n",
      "100%|██████████| 3402/3402 [00:03<00:00, 946.17it/s] \n",
      "100%|██████████| 3402/3402 [00:00<00:00, 6229.09it/s] \n"
     ]
    }
   ],
   "source": [
    "N_STEPS_IN = 12\n",
    "N_STEPS_OUT = 6\n",
    "\n",
    "n_windows = data.shape[1] - (N_STEPS_IN + N_STEPS_OUT)\n",
    "n_stations = data.shape[0]\n",
    "\n",
    "S = station_features(station_array=data.index, station_df=station, n_windows=n_windows)\n",
    "T = time_features(data.columns, N_STEPS_IN, N_STEPS_OUT, n_stations)\n",
    "\n",
    "R, Y = split_sequences(data.values, N_STEPS_IN, N_STEPS_OUT)\n",
    "H = history_sequences(data.values, 12,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X: input sequence\n",
    "- S: station features (category -> embedding)\n",
    "- T: Time features (sin / cos / dow / weekend)\n",
    "- Y: output sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. select output\n",
    "\n",
    "- 최초실험 single output\n",
    "- 예측시점 step2 (index=1) 30분 ~ 1시간 뒤 구간의 충전소 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119070, 6, 3), (119070, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_IDX = 0\n",
    "\n",
    "T = T[:,OUTPUT_IDX,:]\n",
    "Y = Y[:,OUTPUT_IDX, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119070, 3), (119070, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. sequential input 차원변환\n",
    "\n",
    "-  input sequence ->  sequence length * input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119070, 3)\n",
      "(119070, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(H.shape)\n",
    "H = H[:, :, np.newaxis]\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119070, 12)\n",
      "(119070, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "print(R.shape)\n",
    "R = R[:, :, np.newaxis]\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EvcDataset(Dataset):\n",
    "    def __init__(self, rs, hs, ts, ss, ys):\n",
    "        assert len(rs) == len(ys)\n",
    "\n",
    "        self.rs = torch.tensor(rs).float()\n",
    "        self.hs = torch.tensor(hs).float()\n",
    "        self.ts = torch.tensor(ts).int()  # keep int dtype -> goes to embedding layer\n",
    "        self.ss = torch.tensor(ss).int()  # keep int dtype -> goes to embedding layer\n",
    "        self.ys = torch.tensor(ys).float()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r, h, t, s, y = self.rs[i], self.hs[i], self.ts[i], self.ss[i], self.ys[i]\n",
    "        return r, h, t, s, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BaseHybrid(nn.Module):\n",
    "    def __init__(self, hidden_size, station_embedding_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.lstm_r1 = nn.LSTM(1, hidden_size, 1)\n",
    "        self.dropout_r1 = nn.Dropout(p=0.2)\n",
    "        self.fc_r1 = nn.Linear(hidden_size, 16)\n",
    "    \n",
    "        self.lstm_h1 = nn.LSTM(1, hidden_size, 1)\n",
    "        self.dropout_h1 = nn.Dropout(p=0.2)\n",
    "        self.fc_h1 = nn.Linear(hidden_size, 16)\n",
    "\n",
    "        self.station_embedding = nn.Embedding(num_embeddings=2000, embedding_dim=station_embedding_dim)\n",
    "        self.timeslot_embedding = nn.Embedding(num_embeddings=48, embedding_dim=embedding_dim)\n",
    "        self.dow_embedding = nn.Embedding(num_embeddings=7, embedding_dim=embedding_dim)\n",
    "        self.we_embedding = nn.Embedding(num_embeddings=2, embedding_dim=embedding_dim)\n",
    "\n",
    "        self.fc_b1 = nn.Linear(station_embedding_dim+ 3*embedding_dim, 128)\n",
    "        self.fc_b2 = nn.Linear(128, 64)\n",
    "        self.fc_b3 = nn.Linear(64, 64)\n",
    "\n",
    "        self.fc_cat = nn.Linear(32+64, 64)\n",
    "        self.dropout_cat = nn.Dropout(p=0.2)\n",
    "        self.top = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self, r, h, t, s):\n",
    "        # realtime sequence\n",
    "        lstm_out_r, (hn, cn) = self.lstm_r1(r)\n",
    "        last_state_r = lstm_out_r[:,-1,:]\n",
    "        realtime_vec = self.dropout_r1(last_state_r)\n",
    "        realtime_vec = F.relu(self.fc_r1(realtime_vec))\n",
    "        \n",
    "        # history sequence\n",
    "        lstm_out_h, (hn, cn) = self.lstm_h1(h)\n",
    "        last_state_h = lstm_out_h[:,-1,:]\n",
    "        history_vec = self.dropout_h1(last_state_h)\n",
    "        history_vec = F.relu(self.fc_h1(history_vec))\n",
    "\n",
    "        # non-sequenctials\n",
    "        station_vec = self.station_embedding(s[:,0])\n",
    "        timeslot_vec = self.timeslot_embedding(t[:,0])\n",
    "        dow_vec = self.dow_embedding(t[:,1])\n",
    "        we_vec = self.we_embedding(t[:,2])\n",
    "\n",
    "        fc_in = torch.cat((station_vec, timeslot_vec, dow_vec, we_vec), dim=1)\n",
    "        feature_vec = F.relu(self.fc_b1(fc_in))\n",
    "        feature_vec = F.relu(self.fc_b2(feature_vec))\n",
    "        feature_vec = F.relu(self.fc_b3(feature_vec))\n",
    "\n",
    "        # concatenation\n",
    "        cat_vec = torch.cat((realtime_vec, history_vec, feature_vec), dim=1)\n",
    "        fc_out = F.relu(self.fc_cat(cat_vec))\n",
    "        fc_out = self.dropout_cat(fc_out)\n",
    "        fc_out = self.top(fc_out)\n",
    "        return torch.sigmoid(fc_out)\n",
    "\n",
    "\n",
    "class GroupedHybrid(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.lstm_r1 = nn.LSTM(1, hidden_size, 1)\n",
    "        self.dropout_r1 = nn.Dropout(p=0.2)\n",
    "        self.fc_r1 = nn.Linear(hidden_size, 16)\n",
    "    \n",
    "        self.lstm_h1 = nn.LSTM(1, hidden_size, 1)\n",
    "        self.dropout_h1 = nn.Dropout(p=0.2)\n",
    "        self.fc_h1 = nn.Linear(hidden_size, 16)\n",
    "\n",
    "\n",
    "        self.station_embedding = nn.Embedding(num_embeddings=2000, embedding_dim=embedding_dim)\n",
    "        self.dcode_embedding = nn.Embedding(num_embeddings=20, embedding_dim=embedding_dim)\n",
    "        self.fc_b1 = nn.Linear((embedding_dim*2)+3, 128)\n",
    "        self.fc_b2 = nn.Linear(128, 64)\n",
    "        self.fc_b3 = nn.Linear(64, 32)\n",
    "\n",
    "        self.fc_cat = nn.Linear(16*2+32, 128) \n",
    "        self.dropout_cat = nn.Dropout(p=0.2)\n",
    "        self.top = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, r, h, t, s):\n",
    "        # realtime sequence\n",
    "        lstm_out_r, (hn, cn) = self.lstm_r1(r)\n",
    "        last_state_r = lstm_out_r[:,-1,:]\n",
    "        realtime_vec = self.dropout_r1(last_state_r)\n",
    "        realtime_vec = F.relu(self.fc_r1(realtime_vec))\n",
    "        \n",
    "        # realtime sequence\n",
    "        lstm_out_h, (hn, cn) = self.lstm_h1(h)\n",
    "        last_state_h = lstm_out_h[:,-1,:]\n",
    "        history_vec = self.dropout_r1(last_state_h)\n",
    "        history_vec = F.relu(self.fc_h1(history_vec))\n",
    "\n",
    "        # non-sequenctials\n",
    "        station_vec = self.station_embedding(s[:,0])\n",
    "        dcode_vec = self.dcode_embedding(s[:1])\n",
    "\n",
    "        fc_in = torch.cat((station_vec, dcode_vec, t), dim=1)\n",
    "        feature_vec = F.relu(self.fc_b1(fc_in))\n",
    "        feature_vec = F.relu(self.fc_b2(feature_vec))\n",
    "        feature_vec = F.relu(self.fc_b3(feature_vec))\n",
    "\n",
    "        # concatenation\n",
    "        cat_vec = torch.cat((history_vec, feature_vec), dim=1)\n",
    "        fc_out = F.relu(self.fc_cat(cat_vec))\n",
    "        fc_out = self.dropout_cat(fc_out)\n",
    "        fc_out = self.top(fc_out)\n",
    "        return torch.sigmoid(fc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_FRAC = 0.2\n",
    "num_valid = int(3402 * VALID_FRAC) * data.shape[0]\n",
    "\n",
    "trainset = EvcDataset(R[:-num_valid,], H[:-num_valid], T[:-num_valid,], S[:-num_valid,], Y[:-num_valid,])\n",
    "validset = EvcDataset(R[-num_valid:,], H[-num_valid:,], T[-num_valid:,], S[-num_valid:,], Y[-num_valid:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119070, 12, 1), (119070, 3, 1), (119070, 3), (153930, 2), (119070, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape, H.shape, T.shape, S.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95270, 23800)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(validset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(1, 16, 1)\n",
    "out, hidden = rnn(r)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0211e-03,  2.6962e-02, -1.2582e-01,  1.3827e-02,  3.8166e-03,\n",
       "         -3.2350e-02,  2.8341e-03,  2.3226e-02,  2.1473e-02, -2.5127e-03,\n",
       "          4.9307e-02,  1.6179e-02, -5.6218e-02, -1.5274e-02, -4.0569e-02,\n",
       "         -5.1519e-02],\n",
       "        [-1.5412e-02,  2.4869e-02, -1.9483e-01,  1.7900e-02,  2.1373e-02,\n",
       "         -4.1099e-02, -4.5790e-03,  3.1797e-02,  2.9766e-02, -1.4371e-03,\n",
       "          7.1979e-02,  1.6556e-02, -7.2634e-02, -2.1721e-02, -7.5205e-02,\n",
       "         -7.3225e-02],\n",
       "        [-2.0491e-02,  3.9258e-02, -2.5169e-01,  3.7159e-02,  4.2464e-03,\n",
       "         -5.5926e-02, -9.7950e-04,  5.6211e-02,  2.2276e-02,  3.0211e-03,\n",
       "          1.0131e-01,  3.7265e-02, -8.2557e-02, -3.1744e-02, -1.0936e-01,\n",
       "         -7.5722e-02],\n",
       "        [-2.4658e-02,  6.1908e-03, -2.5218e-01,  1.5830e-02,  4.7510e-02,\n",
       "         -3.6343e-02, -2.3426e-02,  3.1158e-02,  3.1563e-02,  7.1803e-04,\n",
       "          8.8331e-02,  4.2758e-03, -7.3128e-02, -2.5658e-02, -1.0889e-01,\n",
       "         -8.3126e-02],\n",
       "        [-2.4884e-02,  2.9486e-02, -2.8720e-01,  3.7802e-02,  1.6610e-02,\n",
       "         -5.3761e-02, -1.0868e-02,  5.6600e-02,  1.9528e-02,  3.1540e-03,\n",
       "          1.1030e-01,  3.1134e-02, -8.2371e-02, -3.4820e-02, -1.2974e-01,\n",
       "         -7.7494e-02],\n",
       "        [-2.6193e-02,  3.7628e-02, -3.0737e-01,  4.8657e-02,  6.3081e-04,\n",
       "         -5.9808e-02, -6.4598e-03,  7.1104e-02,  1.3142e-02,  7.4473e-03,\n",
       "          1.2892e-01,  4.1390e-02, -8.4655e-02, -4.0267e-02, -1.4638e-01,\n",
       "         -7.2866e-02],\n",
       "        [-2.7207e-02,  2.1932e-02, -3.0658e-01,  3.9070e-02,  1.9919e-02,\n",
       "         -5.0737e-02, -1.4496e-02,  6.1561e-02,  1.5320e-02,  6.8856e-03,\n",
       "          1.2822e-01,  2.3093e-02, -8.0269e-02, -3.8083e-02, -1.4380e-01,\n",
       "         -7.4125e-02],\n",
       "        [-2.6158e-02,  3.0763e-02, -3.1912e-01,  4.9259e-02,  5.0664e-03,\n",
       "         -5.6445e-02, -9.3105e-03,  7.3513e-02,  1.0444e-02,  8.3401e-03,\n",
       "          1.3504e-01,  3.4560e-02, -8.3464e-02, -4.1906e-02, -1.5249e-01,\n",
       "         -7.1001e-02],\n",
       "        [-2.6120e-02,  3.6155e-02, -3.2789e-01,  5.6117e-02, -5.4669e-03,\n",
       "         -5.9435e-02, -6.1906e-03,  8.1999e-02,  6.7577e-03,  1.0600e-02,\n",
       "          1.4396e-01,  4.1129e-02, -8.4807e-02, -4.4473e-02, -1.6076e-01,\n",
       "         -6.8320e-02],\n",
       "        [-2.6371e-02,  2.9009e-02, -3.2742e-01,  5.1998e-02,  3.3439e-03,\n",
       "         -5.5147e-02, -9.4641e-03,  7.8038e-02,  7.4149e-03,  1.0314e-02,\n",
       "          1.4496e-01,  3.2169e-02, -8.2963e-02, -4.3367e-02, -1.5924e-01,\n",
       "         -6.8824e-02],\n",
       "        [-2.5645e-02,  3.4615e-02, -3.3385e-01,  5.8538e-02, -6.5546e-03,\n",
       "         -5.8304e-02, -6.3086e-03,  8.5600e-02,  4.7418e-03,  1.1404e-02,\n",
       "          1.4845e-01,  3.9746e-02, -8.4696e-02, -4.5516e-02, -1.6473e-01,\n",
       "         -6.7037e-02],\n",
       "        [-2.6689e-02,  1.0402e-02, -3.1640e-01,  3.8379e-02,  2.7815e-02,\n",
       "         -4.2312e-02, -2.0650e-02,  6.0856e-02,  1.2512e-02,  6.8729e-03,\n",
       "          1.3372e-01,  1.1309e-02, -7.7625e-02, -3.8016e-02, -1.4649e-01,\n",
       "         -7.2270e-02],\n",
       "        [-2.5227e-02,  2.7613e-02, -3.2729e-01,  5.2521e-02,  4.8041e-03,\n",
       "         -5.3309e-02, -1.1092e-02,  7.6068e-02,  8.1391e-03,  7.5555e-03,\n",
       "          1.3786e-01,  3.1335e-02, -8.3767e-02, -4.2480e-02, -1.5428e-01,\n",
       "         -6.9523e-02],\n",
       "        [-2.5677e-02,  3.4425e-02, -3.3292e-01,  5.8565e-02, -6.1060e-03,\n",
       "         -5.7459e-02, -7.2869e-03,  8.3465e-02,  5.5541e-03,  9.7789e-03,\n",
       "          1.4637e-01,  3.9029e-02, -8.5369e-02, -4.4611e-02, -1.6134e-01,\n",
       "         -6.7541e-02],\n",
       "        [-2.7125e-02,  7.2825e-04, -3.0579e-01,  2.9946e-02,  4.1074e-02,\n",
       "         -3.3972e-02, -2.8347e-02,  4.8044e-02,  1.7186e-02,  4.2566e-03,\n",
       "          1.2173e-01,  1.4159e-03, -7.4382e-02, -3.3741e-02, -1.3661e-01,\n",
       "         -7.5348e-02],\n",
       "        [-2.5279e-02,  2.4557e-02, -3.2073e-01,  4.8188e-02,  1.1742e-02,\n",
       "         -5.0258e-02, -1.4115e-02,  6.8260e-02,  1.1083e-02,  5.0040e-03,\n",
       "          1.2937e-01,  2.7350e-02, -8.3240e-02, -3.9913e-02, -1.4696e-01,\n",
       "         -7.1861e-02],\n",
       "        [-2.6671e-02,  1.8172e-02, -3.1669e-01,  4.2257e-02,  2.0509e-02,\n",
       "         -4.7189e-02, -1.7294e-02,  6.2299e-02,  1.3495e-02,  4.8654e-03,\n",
       "          1.3081e-01,  1.9005e-02, -8.1512e-02, -3.8309e-02, -1.4381e-01,\n",
       "         -7.2888e-02],\n",
       "        [-2.7098e-02,  1.9963e-03, -3.0272e-01,  2.8141e-02,  4.3156e-02,\n",
       "         -3.6302e-02, -2.7203e-02,  4.4801e-02,  2.0216e-02,  1.7249e-03,\n",
       "          1.1544e-01,  2.1831e-03, -7.6543e-02, -3.3046e-02, -1.3085e-01,\n",
       "         -7.7063e-02],\n",
       "        [-2.5839e-02,  2.5448e-02, -3.1837e-01,  4.6875e-02,  1.2584e-02,\n",
       "         -5.1671e-02, -1.3841e-02,  6.5623e-02,  1.2865e-02,  3.9140e-03,\n",
       "          1.2705e-01,  2.8105e-02, -8.4014e-02, -3.9386e-02, -1.4347e-01,\n",
       "         -7.2609e-02],\n",
       "        [-2.6685e-02,  2.7005e-02, -3.2180e-01,  4.8684e-02,  9.0043e-03,\n",
       "         -5.3204e-02, -1.2368e-02,  6.9416e-02,  1.1496e-02,  6.1879e-03,\n",
       "          1.3523e-01,  2.9248e-02, -8.4016e-02, -4.0674e-02, -1.4861e-01,\n",
       "         -7.1355e-02],\n",
       "        [-2.7110e-02,  1.3308e-02, -3.1341e-01,  3.7919e-02,  2.7545e-02,\n",
       "         -4.4639e-02, -1.9755e-02,  5.7555e-02,  1.5526e-02,  4.7040e-03,\n",
       "          1.2790e-01,  1.3974e-02, -7.9826e-02, -3.7186e-02, -1.4100e-01,\n",
       "         -7.4002e-02],\n",
       "        [-2.6217e-02,  2.2073e-02, -3.1991e-01,  4.5369e-02,  1.5732e-02,\n",
       "         -5.0540e-02, -1.4513e-02,  6.6169e-02,  1.2622e-02,  5.3016e-03,\n",
       "          1.3120e-01,  2.4161e-02, -8.2835e-02, -3.9788e-02, -1.4574e-01,\n",
       "         -7.2235e-02],\n",
       "        [-2.6045e-02,  3.2624e-02, -3.2854e-01,  5.5079e-02, -9.3977e-04,\n",
       "         -5.6830e-02, -8.7222e-03,  7.7905e-02,  8.2958e-03,  8.1115e-03,\n",
       "          1.4052e-01,  3.6833e-02, -8.5284e-02, -4.3218e-02, -1.5547e-01,\n",
       "         -6.9224e-02],\n",
       "        [-2.7545e-02,  4.0006e-04, -3.0263e-01,  2.7908e-02,  4.3335e-02,\n",
       "         -3.4108e-02, -2.8966e-02,  4.4676e-02,  1.9283e-02,  3.4253e-03,\n",
       "          1.1770e-01,  9.9542e-04, -7.4432e-02, -3.2914e-02, -1.3332e-01,\n",
       "         -7.6377e-02],\n",
       "        [-2.7045e-02, -1.1317e-02, -2.8620e-01,  1.4687e-02,  6.2974e-02,\n",
       "         -2.5320e-02, -3.6916e-02,  2.6499e-02,  2.7249e-02, -1.7872e-03,\n",
       "          9.5162e-02, -1.0805e-02, -7.1555e-02, -2.7220e-02, -1.1747e-01,\n",
       "         -8.1599e-02],\n",
       "        [-2.6913e-02,  2.5951e-03, -2.9258e-01,  2.2422e-02,  5.0133e-02,\n",
       "         -3.6294e-02, -2.8319e-02,  3.4012e-02,  2.5170e-02, -2.8467e-03,\n",
       "          1.0064e-01,  1.4791e-03, -7.7680e-02, -2.9917e-02, -1.1927e-01,\n",
       "         -8.0382e-02],\n",
       "        [-2.6747e-02,  2.6757e-02, -3.1130e-01,  4.2978e-02,  1.5820e-02,\n",
       "         -5.2559e-02, -1.4589e-02,  5.8003e-02,  1.6417e-02,  1.6454e-03,\n",
       "          1.2026e-01,  2.8581e-02, -8.4597e-02, -3.7545e-02, -1.3600e-01,\n",
       "         -7.4577e-02],\n",
       "        [-2.8707e-02, -5.6200e-04, -2.9052e-01,  2.0832e-02,  5.0663e-02,\n",
       "         -3.3513e-02, -3.1448e-02,  3.2750e-02,  2.5942e-02,  7.7071e-05,\n",
       "          1.0387e-01, -8.0097e-04, -7.4676e-02, -2.9685e-02, -1.2224e-01,\n",
       "         -8.0010e-02],\n",
       "        [-2.6679e-02,  2.2737e-02, -3.0895e-01,  3.9899e-02,  2.1300e-02,\n",
       "         -4.9749e-02, -1.6572e-02,  5.5235e-02,  1.7177e-02,  2.2254e-03,\n",
       "          1.1787e-01,  2.4222e-02, -8.2855e-02, -3.6691e-02, -1.3587e-01,\n",
       "         -7.5437e-02],\n",
       "        [-2.8598e-02, -2.1458e-03, -2.8884e-01,  1.9242e-02,  5.2901e-02,\n",
       "         -3.2445e-02, -3.2323e-02,  3.1196e-02,  2.6449e-02, -7.5859e-05,\n",
       "          1.0176e-01, -2.3245e-03, -7.3974e-02, -2.9178e-02, -1.2143e-01,\n",
       "         -8.0411e-02],\n",
       "        [-2.6546e-02,  2.4955e-02, -3.0980e-01,  4.1476e-02,  1.8264e-02,\n",
       "         -5.0954e-02, -1.5568e-02,  5.6895e-02,  1.6403e-02,  2.5174e-03,\n",
       "          1.1842e-01,  2.6868e-02, -8.3295e-02, -3.7156e-02, -1.3708e-01,\n",
       "         -7.4976e-02],\n",
       "        [-2.8652e-02, -1.2177e-03, -2.8926e-01,  1.9871e-02,  5.1628e-02,\n",
       "         -3.2933e-02, -3.1902e-02,  3.2024e-02,  2.5970e-02,  2.6857e-04,\n",
       "          1.0276e-01, -1.4839e-03, -7.4065e-02, -2.9416e-02, -1.2233e-01,\n",
       "         -8.0141e-02]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 16])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(1, 16, 1, batch_first=True)\n",
    "out, hidden = rnn(r)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2015e-02,  6.9692e-02,  2.5801e-01,  9.5976e-02,  3.1905e-02,\n",
       "          4.7648e-02, -1.0323e-01,  1.4276e-02,  1.4304e-02,  7.7959e-03,\n",
       "          1.1104e-01,  7.8984e-03, -1.2351e-01,  1.8536e-02,  1.3944e-01,\n",
       "          2.0081e-01],\n",
       "        [-4.3550e-02,  5.0355e-02,  2.1877e-01,  5.8685e-02, -8.4632e-04,\n",
       "          7.8423e-03, -1.2262e-01,  1.7988e-03, -2.0463e-02,  3.2695e-02,\n",
       "          9.5255e-02,  5.3094e-02, -1.2216e-01,  4.7252e-03,  1.1579e-01,\n",
       "          1.9031e-01],\n",
       "        [-2.8334e-02,  7.6498e-02,  2.7718e-01,  9.7952e-02,  4.5652e-02,\n",
       "          5.2140e-02, -9.5030e-02,  1.5746e-02,  2.4069e-02, -2.1760e-03,\n",
       "          1.1701e-01, -2.9211e-03, -1.2693e-01,  2.4762e-02,  1.4707e-01,\n",
       "          2.0077e-01],\n",
       "        [-5.1653e-02,  3.3647e-02,  1.7348e-01,  3.5897e-02, -3.7829e-02,\n",
       "         -1.6830e-02, -1.4453e-01, -2.4953e-03, -4.8511e-02,  5.0389e-02,\n",
       "          8.2108e-02,  8.1897e-02, -1.1834e-01, -1.4323e-02,  9.7605e-02,\n",
       "          1.8510e-01],\n",
       "        [-2.8798e-02,  7.6266e-02,  2.7724e-01,  1.0144e-01,  4.5094e-02,\n",
       "          5.5078e-02, -9.5143e-02,  1.6222e-02,  2.5576e-02, -2.2991e-03,\n",
       "          1.1802e-01, -5.8200e-03, -1.2542e-01,  2.4979e-02,  1.4780e-01,\n",
       "          2.0269e-01],\n",
       "        [-3.1917e-02,  7.2408e-02,  2.6961e-01,  8.0152e-02,  4.2941e-02,\n",
       "          3.5796e-02, -9.8329e-02,  8.9944e-03,  1.2982e-02,  2.2472e-03,\n",
       "          1.1132e-01,  1.2072e-02, -1.2743e-01,  2.4127e-02,  1.3932e-01,\n",
       "          1.9469e-01],\n",
       "        [-3.4853e-02,  6.3817e-02,  2.4063e-01,  9.0334e-02,  1.9605e-02,\n",
       "          4.0408e-02, -1.1078e-01,  1.2661e-02,  4.0992e-03,  1.6079e-02,\n",
       "          1.0505e-01,  1.9608e-02, -1.2179e-01,  1.2436e-02,  1.3220e-01,\n",
       "          1.9909e-01],\n",
       "        [-3.5889e-02,  6.5377e-02,  2.5666e-01,  7.4647e-02,  2.9930e-02,\n",
       "          2.7348e-02, -1.0506e-01,  6.4260e-03,  3.5880e-03,  1.2884e-02,\n",
       "          1.0749e-01,  2.4570e-02, -1.2577e-01,  1.9189e-02,  1.3260e-01,\n",
       "          1.9413e-01],\n",
       "        [-4.1363e-02,  5.6669e-02,  2.4239e-01,  6.3225e-02,  1.5075e-02,\n",
       "          1.5572e-02, -1.1121e-01,  1.0129e-03, -1.0438e-02,  2.2872e-02,\n",
       "          1.0539e-01,  3.7764e-02, -1.2558e-01,  1.3102e-02,  1.2481e-01,\n",
       "          1.9250e-01],\n",
       "        [-4.2186e-02,  5.4635e-02,  2.3308e-01,  4.8882e-02,  1.1297e-02,\n",
       "          2.9863e-03, -1.1588e-01, -2.3628e-03, -1.8657e-02,  2.6416e-02,\n",
       "          9.6319e-02,  5.2374e-02, -1.2644e-01,  1.0791e-02,  1.1839e-01,\n",
       "          1.8600e-01],\n",
       "        [-2.8461e-02,  7.6268e-02,  2.7679e-01,  9.6048e-02,  4.5605e-02,\n",
       "          5.0276e-02, -9.5258e-02,  1.5250e-02,  2.3077e-02, -1.8078e-03,\n",
       "          1.1628e-01, -1.1894e-03, -1.2719e-01,  2.4781e-02,  1.4647e-01,\n",
       "          1.9998e-01],\n",
       "        [-4.5808e-02,  4.5547e-02,  2.0302e-01,  5.3241e-02, -1.2236e-02,\n",
       "          1.1312e-03, -1.3015e-01,  1.1158e-03, -2.8539e-02,  3.8348e-02,\n",
       "          8.9795e-02,  6.1857e-02, -1.2007e-01, -1.0143e-03,  1.0994e-01,\n",
       "          1.8901e-01],\n",
       "        [-2.8561e-02,  7.6402e-02,  2.7727e-01,  1.0008e-01,  4.5346e-02,\n",
       "          5.3891e-02, -9.5083e-02,  1.6108e-02,  2.5020e-02, -2.2578e-03,\n",
       "          1.1760e-01, -4.6239e-03, -1.2607e-01,  2.4886e-02,  1.4754e-01,\n",
       "          2.0192e-01],\n",
       "        [-2.9185e-02,  7.5320e-02,  2.7458e-01,  8.7610e-02,  4.5719e-02,\n",
       "          4.3339e-02, -9.5896e-02,  1.2491e-02,  1.8448e-02, -8.8123e-04,\n",
       "          1.1402e-01,  5.2122e-03, -1.2862e-01,  2.4482e-02,  1.4351e-01,\n",
       "          1.9640e-01],\n",
       "        [-5.3498e-02,  3.0716e-02,  1.6914e-01,  3.4049e-02, -4.3757e-02,\n",
       "         -1.9123e-02, -1.4693e-01, -3.4341e-03, -5.1603e-02,  5.3101e-02,\n",
       "          8.1606e-02,  8.4496e-02, -1.1746e-01, -1.6401e-02,  9.5781e-02,\n",
       "          1.8565e-01],\n",
       "        [-2.8141e-02,  7.6585e-02,  2.7732e-01,  9.7196e-02,  4.5721e-02,\n",
       "          5.1589e-02, -9.4939e-02,  1.5643e-02,  2.3722e-02, -2.1713e-03,\n",
       "          1.1680e-01, -2.4203e-03, -1.2742e-01,  2.4687e-02,  1.4705e-01,\n",
       "          2.0030e-01],\n",
       "        [-3.9894e-02,  5.6953e-02,  2.3126e-01,  6.4510e-02,  1.2105e-02,\n",
       "          1.5283e-02, -1.1637e-01,  4.0512e-03, -1.1331e-02,  2.4582e-02,\n",
       "          9.7858e-02,  4.3120e-02, -1.2338e-01,  1.0209e-02,  1.2165e-01,\n",
       "          1.9081e-01],\n",
       "        [-4.9672e-02,  3.9266e-02,  1.9024e-01,  2.8329e-02, -2.2801e-02,\n",
       "         -1.9960e-02, -1.3649e-01, -6.3789e-03, -4.4402e-02,  4.4371e-02,\n",
       "          8.2289e-02,  8.1210e-02, -1.2227e-01, -6.2664e-03,  1.0071e-01,\n",
       "          1.8098e-01],\n",
       "        [-2.8798e-02,  7.6266e-02,  2.7724e-01,  1.0144e-01,  4.5094e-02,\n",
       "          5.5078e-02, -9.5143e-02,  1.6222e-02,  2.5576e-02, -2.2991e-03,\n",
       "          1.1802e-01, -5.8200e-03, -1.2542e-01,  2.4979e-02,  1.4780e-01,\n",
       "          2.0269e-01],\n",
       "        [-3.3005e-02,  6.9083e-02,  2.5845e-01,  8.9928e-02,  3.2958e-02,\n",
       "          4.1832e-02, -1.0335e-01,  1.2060e-02,  1.2107e-02,  8.3606e-03,\n",
       "          1.0998e-01,  1.1901e-02, -1.2383e-01,  1.9628e-02,  1.3772e-01,\n",
       "          1.9890e-01],\n",
       "        [-5.6041e-02,  3.1716e-02,  1.8443e-01,  3.5909e-03, -3.2622e-02,\n",
       "         -3.8339e-02, -1.3901e-01, -1.7444e-02, -6.0043e-02,  4.9601e-02,\n",
       "          7.9021e-02,  9.7608e-02, -1.2480e-01, -9.4287e-03,  9.2673e-02,\n",
       "          1.7511e-01],\n",
       "        [-3.7463e-02,  6.2226e-02,  2.4731e-01,  7.0557e-02,  2.3618e-02,\n",
       "          2.2575e-02, -1.0920e-01,  5.3410e-03, -2.0522e-03,  1.7343e-02,\n",
       "          1.0366e-01,  3.2011e-02, -1.2483e-01,  1.6051e-02,  1.2831e-01,\n",
       "          1.9271e-01],\n",
       "        [-3.6126e-02,  6.6730e-02,  2.5965e-01,  7.5276e-02,  3.3697e-02,\n",
       "          2.9102e-02, -1.0306e-01,  5.6601e-03,  5.4628e-03,  9.5773e-03,\n",
       "          1.0924e-01,  1.9364e-02, -1.2524e-01,  2.1422e-02,  1.3408e-01,\n",
       "          1.9517e-01],\n",
       "        [-6.1016e-02,  2.0581e-02,  1.5437e-01, -1.9925e-02, -6.0237e-02,\n",
       "         -5.9912e-02, -1.5514e-01, -2.1486e-02, -8.0144e-02,  6.0117e-02,\n",
       "          6.8145e-02,  1.1870e-01, -1.2344e-01, -2.3804e-02,  8.0372e-02,\n",
       "          1.6886e-01],\n",
       "        [-4.9196e-02,  3.6958e-02,  1.7856e-01,  4.1859e-02, -3.2675e-02,\n",
       "         -1.0673e-02, -1.4156e-01, -1.3865e-04, -4.3854e-02,  4.7350e-02,\n",
       "          8.3872e-02,  7.6177e-02, -1.1931e-01, -1.2774e-02,  1.0091e-01,\n",
       "          1.8597e-01],\n",
       "        [-5.2833e-02,  3.6473e-02,  1.9325e-01,  2.8258e-02, -2.4495e-02,\n",
       "         -1.9689e-02, -1.3448e-01, -9.2953e-03, -4.5960e-02,  4.6010e-02,\n",
       "          8.6561e-02,  8.0512e-02, -1.2208e-01, -5.3741e-03,  1.0037e-01,\n",
       "          1.8330e-01],\n",
       "        [-2.8798e-02,  7.6266e-02,  2.7724e-01,  1.0144e-01,  4.5094e-02,\n",
       "          5.5078e-02, -9.5143e-02,  1.6222e-02,  2.5576e-02, -2.2991e-03,\n",
       "          1.1802e-01, -5.8200e-03, -1.2542e-01,  2.4979e-02,  1.4780e-01,\n",
       "          2.0269e-01],\n",
       "        [-6.1016e-02,  2.0581e-02,  1.5437e-01, -1.9925e-02, -6.0237e-02,\n",
       "         -5.9912e-02, -1.5514e-01, -2.1486e-02, -8.0144e-02,  6.0117e-02,\n",
       "          6.8145e-02,  1.1870e-01, -1.2344e-01, -2.3804e-02,  8.0372e-02,\n",
       "          1.6886e-01],\n",
       "        [-3.5763e-02,  6.5123e-02,  2.5583e-01,  7.6799e-02,  2.8641e-02,\n",
       "          2.8922e-02, -1.0543e-01,  7.3101e-03,  3.9944e-03,  1.3507e-02,\n",
       "          1.0789e-01,  2.3938e-02, -1.2553e-01,  1.8460e-02,  1.3286e-01,\n",
       "          1.9493e-01],\n",
       "        [-4.4032e-02,  4.5192e-02,  1.9247e-01,  6.0139e-02, -1.8869e-02,\n",
       "          7.1400e-03, -1.3414e-01,  5.5571e-03, -2.9533e-02,  3.8989e-02,\n",
       "          8.8356e-02,  5.8706e-02, -1.1919e-01, -6.7145e-03,  1.1004e-01,\n",
       "          1.9051e-01],\n",
       "        [-2.8514e-02,  7.6310e-02,  2.7668e-01,  9.6190e-02,  4.5791e-02,\n",
       "          5.0563e-02, -9.5199e-02,  1.5224e-02,  2.3169e-02, -1.9754e-03,\n",
       "          1.1650e-01, -1.4156e-03, -1.2712e-01,  2.4755e-02,  1.4636e-01,\n",
       "          2.0002e-01],\n",
       "        [-4.9794e-02,  3.5500e-02,  1.7604e-01,  3.3184e-02, -3.5492e-02,\n",
       "         -1.7646e-02, -1.4281e-01, -2.4197e-03, -4.8797e-02,  4.8938e-02,\n",
       "          8.1762e-02,  8.2260e-02, -1.2114e-01, -1.4423e-02,  9.8596e-02,\n",
       "          1.8278e-01]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def train(model, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    for b_i, (R, H, T, S, y) in enumerate(train_dataloader):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        pred = model(R, H, T, S)\n",
    "    \n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if b_i % 3000 == 0:\n",
    "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                epoch, b_i * len(R), len(train_dataloader.dataset),\n",
    "                100 * b_i / len(train_dataloader), loss.item()\n",
    "            ))\n",
    "\n",
    "def calc_accuracy(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    return 1- (torch.norm(error) / torch.norm(y_true))\n",
    "\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_total = torch.Tensor()\n",
    "        y_total = torch.Tensor()\n",
    "\n",
    "        for R, H, T, S, y in test_dataloader:\n",
    "            pred = model(R, H, T, S)\n",
    "            loss += criterion(pred, y).item()\n",
    "            pred_total = torch.cat((pred_total, pred.flatten()), dim=0)\n",
    "            y_total = torch.cat((y_total, y.flatten()), dim=0)\n",
    "\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    accuracy = calc_accuracy(y_total, pred_total)\n",
    "    r2 = r2_score(y_total, pred_total)\n",
    "\n",
    "    print('\\nTest dataset:  Loss: {:.4f}, Accuracy: {:.4f}, R2: {:.4f}'.format(loss, accuracy, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/680500 (0%)]\t training loss: 0.204155\n",
      "epoch: 1 [96000/680500 (14%)]\t training loss: 0.175144\n",
      "epoch: 1 [192000/680500 (28%)]\t training loss: 0.182654\n",
      "epoch: 1 [288000/680500 (42%)]\t training loss: 0.049516\n",
      "epoch: 1 [384000/680500 (56%)]\t training loss: 0.044217\n",
      "epoch: 1 [480000/680500 (71%)]\t training loss: 0.111849\n",
      "epoch: 1 [576000/680500 (85%)]\t training loss: 0.055007\n",
      "epoch: 1 [672000/680500 (99%)]\t training loss: 0.098865\n",
      "\n",
      "Test dataset:  Loss: 0.1085, Accuracy: 0.6375, R2: -0.2256\n",
      "\n",
      "epoch: 2 [0/680500 (0%)]\t training loss: 0.141608\n",
      "epoch: 2 [96000/680500 (14%)]\t training loss: 0.135399\n",
      "epoch: 2 [192000/680500 (28%)]\t training loss: 0.154411\n",
      "epoch: 2 [288000/680500 (42%)]\t training loss: 0.096525\n",
      "epoch: 2 [384000/680500 (56%)]\t training loss: 0.157500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11842/4081860314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11842/4209276475.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, optim, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11842/1290460226.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, r, h, t, s)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mcat_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealtime_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mfc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mfc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mfc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/lib/python3.8/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BaseHybrid(hidden_size=32, station_embedding_dim=30, embedding_dim=16)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "N_EPOCH = 10\n",
    "\n",
    "\n",
    "for epoch in range(1,N_EPOCH+1):\n",
    "    train(model, train_loader, optim, epoch)\n",
    "    test(model, valid_loader)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/989750 (0%)]\t training loss: 0.350602\n",
      "epoch: 1 [128000/989750 (13%)]\t training loss: 0.084415\n",
      "epoch: 1 [256000/989750 (26%)]\t training loss: 0.071936\n",
      "epoch: 1 [384000/989750 (39%)]\t training loss: 0.092929\n",
      "epoch: 1 [512000/989750 (52%)]\t training loss: 0.081366\n",
      "epoch: 1 [640000/989750 (65%)]\t training loss: 0.090697\n",
      "epoch: 1 [768000/989750 (78%)]\t training loss: 0.092088\n",
      "epoch: 1 [896000/989750 (91%)]\t training loss: 0.067785\n",
      "\n",
      "Test dataset:  Loss: 0.0788, Accuracy: 0.6909, R2: 0.1170\n",
      "\n",
      "epoch: 2 [0/989750 (0%)]\t training loss: 0.064013\n",
      "epoch: 2 [128000/989750 (13%)]\t training loss: 0.054172\n",
      "epoch: 2 [256000/989750 (26%)]\t training loss: 0.080805\n",
      "epoch: 2 [384000/989750 (39%)]\t training loss: 0.087845\n",
      "epoch: 2 [512000/989750 (52%)]\t training loss: 0.103007\n",
      "epoch: 2 [640000/989750 (65%)]\t training loss: 0.054350\n",
      "epoch: 2 [768000/989750 (78%)]\t training loss: 0.077808\n",
      "epoch: 2 [896000/989750 (91%)]\t training loss: 0.085690\n",
      "\n",
      "Test dataset:  Loss: 0.0779, Accuracy: 0.6927, R2: 0.1268\n",
      "\n",
      "epoch: 3 [0/989750 (0%)]\t training loss: 0.092530\n",
      "epoch: 3 [128000/989750 (13%)]\t training loss: 0.095581\n",
      "epoch: 3 [256000/989750 (26%)]\t training loss: 0.073451\n",
      "epoch: 3 [384000/989750 (39%)]\t training loss: 0.077755\n",
      "epoch: 3 [512000/989750 (52%)]\t training loss: 0.106952\n",
      "epoch: 3 [640000/989750 (65%)]\t training loss: 0.070944\n",
      "epoch: 3 [768000/989750 (78%)]\t training loss: 0.083838\n",
      "epoch: 3 [896000/989750 (91%)]\t training loss: 0.080097\n",
      "\n",
      "Test dataset:  Loss: 0.0775, Accuracy: 0.6934, R2: 0.1313\n",
      "\n",
      "epoch: 4 [0/989750 (0%)]\t training loss: 0.077430\n",
      "epoch: 4 [128000/989750 (13%)]\t training loss: 0.105195\n",
      "epoch: 4 [256000/989750 (26%)]\t training loss: 0.087240\n",
      "epoch: 4 [384000/989750 (39%)]\t training loss: 0.069857\n",
      "epoch: 4 [512000/989750 (52%)]\t training loss: 0.047256\n",
      "epoch: 4 [640000/989750 (65%)]\t training loss: 0.073240\n",
      "epoch: 4 [768000/989750 (78%)]\t training loss: 0.104141\n",
      "epoch: 4 [896000/989750 (91%)]\t training loss: 0.104555\n",
      "\n",
      "Test dataset:  Loss: 0.0777, Accuracy: 0.6931, R2: 0.1295\n",
      "\n",
      "epoch: 5 [0/989750 (0%)]\t training loss: 0.068172\n",
      "epoch: 5 [128000/989750 (13%)]\t training loss: 0.050784\n",
      "epoch: 5 [256000/989750 (26%)]\t training loss: 0.067358\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [112], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m N_EPOCH \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,N_EPOCH\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     train(model_2, train_loader, optim, epoch)\n\u001b[1;32m      8\u001b[0m     test(model_2, valid_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn [111], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, optim, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m b_i, (X, T, S, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      8\u001b[0m     optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m     pred \u001b[39m=\u001b[39m model(X,T,S)\n\u001b[1;32m     11\u001b[0m     loss \u001b[39m=\u001b[39m criterion(pred, y)\n\u001b[1;32m     12\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [103], line 56\u001b[0m, in \u001b[0;36mGroupedHybrid.forward\u001b[0;34m(self, x, t, s)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, t, s):\n\u001b[0;32m---> 56\u001b[0m     lstm_out, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     57\u001b[0m     last_state \u001b[39m=\u001b[39m lstm_out[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n\u001b[1;32m     58\u001b[0m     station_vec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstation_embedding(s[:,\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    770\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    773\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_2 = GroupedHybrid(hidden_size=16, embedding_dim=16)\n",
    "optim = torch.optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "\n",
    "N_EPOCH = 20\n",
    "\n",
    "for epoch in range(1,N_EPOCH+1):\n",
    "    train(model_2, train_loader, optim, epoch)\n",
    "    test(model_2, valid_loader)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8b0b9810b90ece1a2c30b007939a77bea2a3bd150b1467149252c930670344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
