{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/input_table/pre_dataset.csv')\n",
    "data = data.sample(frac=1, random_state=42, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.station.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18105744520030234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['t+6'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t0</th>\n",
       "      <th>station</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>dow</th>\n",
       "      <th>weekend</th>\n",
       "      <th>t+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.173648</td>\n",
       "      <td>-0.984808</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>-0.953717</td>\n",
       "      <td>-0.300706</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300706</td>\n",
       "      <td>0.953717</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t-11  t-10  t-9  t-8  t-7  t-6  t-5  t-4  t-3  t-2  t-1  t0  station  \\\n",
       "0     0     0    0    0    0    1    1    1    1    1    1   0       16   \n",
       "1     0     0    0    0    0    0    0    0    0    0    0   0       28   \n",
       "2     0     0    0    0    0    0    0    0    0    0    0   0       86   \n",
       "3     1     1    1    1    0    0    0    0    0    0    0   0       72   \n",
       "4     0     0    0    0    0    0    0    0    0    0    0   0        9   \n",
       "\n",
       "   sin_time  cos_time  dow  weekend  t+6  \n",
       "0 -0.173648 -0.984808    4        0    0  \n",
       "1 -0.258819  0.965926    2        0    0  \n",
       "2  0.991445  0.130526    5        1    0  \n",
       "3 -0.953717 -0.300706    2        0    0  \n",
       "4  0.300706  0.953717    6        1    0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323000, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 323000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_NUM = 1_000_000\n",
    "train_data = data.iloc[:TRAIN_NUM]\n",
    "valid_data = data.iloc[TRAIN_NUM:]\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature definition\n",
    "general_features = [col for col in data.columns if col not in ['station', 't+6']]\n",
    "embedding_features = ['station']\n",
    "target_features = ['t+6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[general_features].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EvcBaseDataset(Dataset):\n",
    "    def __init__(self, xs, ys):\n",
    "        assert len(xs) == len(ys)\n",
    "\n",
    "        self.xs = torch.tensor(xs).float()\n",
    "        self.ys = torch.tensor(ys).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.xs[i], self.ys[i]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class EvcEmbeddingDataset(EvcBaseDataset):\n",
    "    def __init__(self, xs, es, ys):\n",
    "        assert len(xs) == len(ys)\n",
    "\n",
    "        self.xs = torch.tensor(xs).float()\n",
    "        self.es = torch.tensor(es)\n",
    "        self.ys = torch.tensor(ys).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, e, y = self.xs[i], self.es[i], self.ys[i]\n",
    "        return x, e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_base = EvcBaseDataset(xs=train_data[general_features].values,\n",
    "                               ys=train_data[target_features].values)\n",
    "validset_base = EvcBaseDataset(xs=valid_data[general_features].values,\n",
    "                               ys=valid_data[target_features].values)               \n",
    "\n",
    "\n",
    "trainset_emb = EvcEmbeddingDataset(xs=train_data[general_features].values,\n",
    "                                   es=train_data[embedding_features].values.flatten(),\n",
    "                                   ys=train_data[target_features].values)\n",
    "validset_emb = EvcEmbeddingDataset(xs=valid_data[general_features].values,\n",
    "                                   es=valid_data[embedding_features].values.flatten(),\n",
    "                                   ys=valid_data[target_features].values)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_base = DataLoader(trainset_base, batch_size=256)\n",
    "valid_loader_base = DataLoader(validset_base, batch_size=1024)\n",
    "\n",
    "train_loader_emb = DataLoader(trainset_emb, batch_size=256)\n",
    "valid_loader_emb = DataLoader(validset_emb, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BaseMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class BaseEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, station_size, n_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=station_size, embedding_dim=n_dim)\n",
    "        self.fc1 = nn.Linear(16+n_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, e):\n",
    "        e = self.embedding(e)\n",
    "        x = torch.cat((x, e), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train(model, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    for b_i, (X, y) in enumerate(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        pred_prob = model(X)\n",
    "        loss = criterion(pred_prob, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if b_i % 1000 == 0:\n",
    "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                epoch, b_i * len(X), len(train_dataloader.dataset),\n",
    "                100 * b_i / len(train_dataloader), loss.item()\n",
    "            ))\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    loss = 0\n",
    "    # success = 0\n",
    "    with torch.no_grad():\n",
    "        pred_prob_total = torch.Tensor()\n",
    "        y_total = torch.Tensor()\n",
    "\n",
    "        for X, y in test_dataloader:\n",
    "            prob_pred = model(X)\n",
    "            pred_prob_total = torch.cat([pred_prob_total, prob_pred.flatten()], dim=0)\n",
    "            y_total = torch.cat([y_total, y.flatten()], dim=0)\n",
    "\n",
    "            loss += criterion(prob_pred, y).item()\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "\n",
    "    y_pred = torch.round(pred_prob_total)\n",
    "    accuracy = accuracy_score(y_total, y_pred)\n",
    "    precision = precision_score(y_total, y_pred)\n",
    "    recall = recall_score(y_total, y_pred)\n",
    "    f1 = f1_score(y_total, y_pred)\n",
    "\n",
    "    auc_score = roc_auc_score(y_total, pred_prob_total)\n",
    "    print('\\nTest dataset:  Loss: {:.4f}, Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1: {:.2f}, AUC: {:.2f}'.format(\n",
    "        loss, accuracy, precision, recall, f1, auc_score))\n",
    "\n",
    "\n",
    "def train_embnet(model, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    for b_i, (X, E, y) in enumerate(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        pred_prob = model(X,E)\n",
    "        loss = criterion(pred_prob, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if b_i % 1000 == 0:\n",
    "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                epoch, b_i * len(X), len(train_dataloader.dataset),\n",
    "                100 * b_i / len(train_dataloader), loss.item()\n",
    "            ))\n",
    "\n",
    "def test_embnet(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    loss = 0\n",
    "    # success = 0\n",
    "    with torch.no_grad():\n",
    "        pred_prob_total = torch.Tensor()\n",
    "        y_total = torch.Tensor()\n",
    "\n",
    "        for X, E, y in test_dataloader:\n",
    "            prob_pred = model(X, E)\n",
    "            pred_prob_total = torch.cat([pred_prob_total, prob_pred.flatten()], dim=0)\n",
    "            y_total = torch.cat([y_total, y.flatten()], dim=0)\n",
    "\n",
    "            loss += criterion(prob_pred, y).item()\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "\n",
    "    y_pred = torch.round(pred_prob_total)\n",
    "    accuracy = accuracy_score(y_total, y_pred)\n",
    "    precision = precision_score(y_total, y_pred)\n",
    "    recall = recall_score(y_total, y_pred)\n",
    "    f1 = f1_score(y_total, y_pred)\n",
    "\n",
    "    auc_score = roc_auc_score(y_total, pred_prob_total)\n",
    "    print('\\nTest dataset:  Loss: {:.4f}, Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1: {:.2f}, AUC: {:.2f}'.format(\n",
    "        loss, accuracy, precision, recall, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/1000000 (0%)]\t training loss: 0.645223\n",
      "epoch: 1 [256000/1000000 (26%)]\t training loss: 0.469892\n",
      "epoch: 1 [512000/1000000 (51%)]\t training loss: 0.428282\n",
      "epoch: 1 [768000/1000000 (77%)]\t training loss: 0.426832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4343, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 2 [0/1000000 (0%)]\t training loss: 0.425665\n",
      "epoch: 2 [256000/1000000 (26%)]\t training loss: 0.469160\n",
      "epoch: 2 [512000/1000000 (51%)]\t training loss: 0.426998\n",
      "epoch: 2 [768000/1000000 (77%)]\t training loss: 0.425887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4341, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 3 [0/1000000 (0%)]\t training loss: 0.427071\n",
      "epoch: 3 [256000/1000000 (26%)]\t training loss: 0.469432\n",
      "epoch: 3 [512000/1000000 (51%)]\t training loss: 0.426594\n",
      "epoch: 3 [768000/1000000 (77%)]\t training loss: 0.426085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4340, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 4 [0/1000000 (0%)]\t training loss: 0.427153\n",
      "epoch: 4 [256000/1000000 (26%)]\t training loss: 0.469212\n",
      "epoch: 4 [512000/1000000 (51%)]\t training loss: 0.426253\n",
      "epoch: 4 [768000/1000000 (77%)]\t training loss: 0.426167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4339, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 5 [0/1000000 (0%)]\t training loss: 0.427444\n",
      "epoch: 5 [256000/1000000 (26%)]\t training loss: 0.469082\n",
      "epoch: 5 [512000/1000000 (51%)]\t training loss: 0.426329\n",
      "epoch: 5 [768000/1000000 (77%)]\t training loss: 0.425793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4339, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 6 [0/1000000 (0%)]\t training loss: 0.427282\n",
      "epoch: 6 [256000/1000000 (26%)]\t training loss: 0.468474\n",
      "epoch: 6 [512000/1000000 (51%)]\t training loss: 0.426733\n",
      "epoch: 6 [768000/1000000 (77%)]\t training loss: 0.425806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easttuna/projects/ev-charger-occupancy-prediction/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset:  Loss: 0.4338, Accuracy: 0.82, Precision: 0.00, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 7 [0/1000000 (0%)]\t training loss: 0.426976\n",
      "epoch: 7 [256000/1000000 (26%)]\t training loss: 0.467565\n",
      "epoch: 7 [512000/1000000 (51%)]\t training loss: 0.426658\n",
      "epoch: 7 [768000/1000000 (77%)]\t training loss: 0.425630\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.25, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 8 [0/1000000 (0%)]\t training loss: 0.427747\n",
      "epoch: 8 [256000/1000000 (26%)]\t training loss: 0.466863\n",
      "epoch: 8 [512000/1000000 (51%)]\t training loss: 0.426090\n",
      "epoch: 8 [768000/1000000 (77%)]\t training loss: 0.425775\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.44, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 9 [0/1000000 (0%)]\t training loss: 0.427903\n",
      "epoch: 9 [256000/1000000 (26%)]\t training loss: 0.467252\n",
      "epoch: 9 [512000/1000000 (51%)]\t training loss: 0.426188\n",
      "epoch: 9 [768000/1000000 (77%)]\t training loss: 0.425218\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.45, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 10 [0/1000000 (0%)]\t training loss: 0.428001\n",
      "epoch: 10 [256000/1000000 (26%)]\t training loss: 0.466549\n",
      "epoch: 10 [512000/1000000 (51%)]\t training loss: 0.426501\n",
      "epoch: 10 [768000/1000000 (77%)]\t training loss: 0.424990\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.45, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 11 [0/1000000 (0%)]\t training loss: 0.427796\n",
      "epoch: 11 [256000/1000000 (26%)]\t training loss: 0.466968\n",
      "epoch: 11 [512000/1000000 (51%)]\t training loss: 0.426949\n",
      "epoch: 11 [768000/1000000 (77%)]\t training loss: 0.424731\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.52, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 12 [0/1000000 (0%)]\t training loss: 0.427418\n",
      "epoch: 12 [256000/1000000 (26%)]\t training loss: 0.466685\n",
      "epoch: 12 [512000/1000000 (51%)]\t training loss: 0.426902\n",
      "epoch: 12 [768000/1000000 (77%)]\t training loss: 0.424460\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.41, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 13 [0/1000000 (0%)]\t training loss: 0.427574\n",
      "epoch: 13 [256000/1000000 (26%)]\t training loss: 0.466503\n",
      "epoch: 13 [512000/1000000 (51%)]\t training loss: 0.426795\n",
      "epoch: 13 [768000/1000000 (77%)]\t training loss: 0.424131\n",
      "\n",
      "Test dataset:  Loss: 0.4337, Accuracy: 0.82, Precision: 0.41, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 14 [0/1000000 (0%)]\t training loss: 0.427822\n",
      "epoch: 14 [256000/1000000 (26%)]\t training loss: 0.466261\n",
      "epoch: 14 [512000/1000000 (51%)]\t training loss: 0.426202\n",
      "epoch: 14 [768000/1000000 (77%)]\t training loss: 0.424211\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.47, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 15 [0/1000000 (0%)]\t training loss: 0.427804\n",
      "epoch: 15 [256000/1000000 (26%)]\t training loss: 0.465794\n",
      "epoch: 15 [512000/1000000 (51%)]\t training loss: 0.425957\n",
      "epoch: 15 [768000/1000000 (77%)]\t training loss: 0.424435\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.40, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 16 [0/1000000 (0%)]\t training loss: 0.427628\n",
      "epoch: 16 [256000/1000000 (26%)]\t training loss: 0.465577\n",
      "epoch: 16 [512000/1000000 (51%)]\t training loss: 0.426057\n",
      "epoch: 16 [768000/1000000 (77%)]\t training loss: 0.424797\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.42, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 17 [0/1000000 (0%)]\t training loss: 0.427505\n",
      "epoch: 17 [256000/1000000 (26%)]\t training loss: 0.465340\n",
      "epoch: 17 [512000/1000000 (51%)]\t training loss: 0.426074\n",
      "epoch: 17 [768000/1000000 (77%)]\t training loss: 0.425435\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.36, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 18 [0/1000000 (0%)]\t training loss: 0.427451\n",
      "epoch: 18 [256000/1000000 (26%)]\t training loss: 0.465407\n",
      "epoch: 18 [512000/1000000 (51%)]\t training loss: 0.426006\n",
      "epoch: 18 [768000/1000000 (77%)]\t training loss: 0.425247\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.43, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 19 [0/1000000 (0%)]\t training loss: 0.427824\n",
      "epoch: 19 [256000/1000000 (26%)]\t training loss: 0.464709\n",
      "epoch: 19 [512000/1000000 (51%)]\t training loss: 0.425739\n",
      "epoch: 19 [768000/1000000 (77%)]\t training loss: 0.425085\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.39, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n",
      "epoch: 20 [0/1000000 (0%)]\t training loss: 0.427829\n",
      "epoch: 20 [256000/1000000 (26%)]\t training loss: 0.464661\n",
      "epoch: 20 [512000/1000000 (51%)]\t training loss: 0.425514\n",
      "epoch: 20 [768000/1000000 (77%)]\t training loss: 0.425096\n",
      "\n",
      "Test dataset:  Loss: 0.4336, Accuracy: 0.82, Precision: 0.39, Recall: 0.00, F1: 0.00, AUC: 0.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseMLP()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1,21):\n",
    "    train(model, train_loader_base, optim, epoch)\n",
    "    test(model, valid_loader_base)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/1000000 (0%)]\t training loss: 0.744254\n",
      "epoch: 1 [256000/1000000 (26%)]\t training loss: 0.459911\n",
      "epoch: 1 [512000/1000000 (51%)]\t training loss: 0.418175\n",
      "epoch: 1 [768000/1000000 (77%)]\t training loss: 0.411327\n",
      "\n",
      "Test dataset:  Loss: 0.4180, Accuracy: 0.82, Precision: 0.58, Recall: 0.03, F1: 0.06, AUC: 0.73\n",
      "\n",
      "epoch: 2 [0/1000000 (0%)]\t training loss: 0.417620\n",
      "epoch: 2 [256000/1000000 (26%)]\t training loss: 0.452626\n",
      "epoch: 2 [512000/1000000 (51%)]\t training loss: 0.414956\n",
      "epoch: 2 [768000/1000000 (77%)]\t training loss: 0.397283\n",
      "\n",
      "Test dataset:  Loss: 0.4146, Accuracy: 0.82, Precision: 0.57, Recall: 0.04, F1: 0.07, AUC: 0.74\n",
      "\n",
      "epoch: 3 [0/1000000 (0%)]\t training loss: 0.420862\n",
      "epoch: 3 [256000/1000000 (26%)]\t training loss: 0.446642\n",
      "epoch: 3 [512000/1000000 (51%)]\t training loss: 0.413234\n",
      "epoch: 3 [768000/1000000 (77%)]\t training loss: 0.394477\n",
      "\n",
      "Test dataset:  Loss: 0.4130, Accuracy: 0.82, Precision: 0.58, Recall: 0.04, F1: 0.08, AUC: 0.74\n",
      "\n",
      "epoch: 4 [0/1000000 (0%)]\t training loss: 0.422190\n",
      "epoch: 4 [256000/1000000 (26%)]\t training loss: 0.437921\n",
      "epoch: 4 [512000/1000000 (51%)]\t training loss: 0.413041\n",
      "epoch: 4 [768000/1000000 (77%)]\t training loss: 0.391447\n",
      "\n",
      "Test dataset:  Loss: 0.4119, Accuracy: 0.82, Precision: 0.58, Recall: 0.05, F1: 0.09, AUC: 0.74\n",
      "\n",
      "epoch: 5 [0/1000000 (0%)]\t training loss: 0.422227\n",
      "epoch: 5 [256000/1000000 (26%)]\t training loss: 0.433555\n",
      "epoch: 5 [512000/1000000 (51%)]\t training loss: 0.413417\n",
      "epoch: 5 [768000/1000000 (77%)]\t training loss: 0.391468\n",
      "\n",
      "Test dataset:  Loss: 0.4108, Accuracy: 0.82, Precision: 0.58, Recall: 0.05, F1: 0.09, AUC: 0.75\n",
      "\n",
      "epoch: 6 [0/1000000 (0%)]\t training loss: 0.418448\n",
      "epoch: 6 [256000/1000000 (26%)]\t training loss: 0.431192\n",
      "epoch: 6 [512000/1000000 (51%)]\t training loss: 0.410428\n",
      "epoch: 6 [768000/1000000 (77%)]\t training loss: 0.391755\n",
      "\n",
      "Test dataset:  Loss: 0.4098, Accuracy: 0.82, Precision: 0.59, Recall: 0.05, F1: 0.09, AUC: 0.75\n",
      "\n",
      "epoch: 7 [0/1000000 (0%)]\t training loss: 0.419581\n",
      "epoch: 7 [256000/1000000 (26%)]\t training loss: 0.426802\n",
      "epoch: 7 [512000/1000000 (51%)]\t training loss: 0.407310\n",
      "epoch: 7 [768000/1000000 (77%)]\t training loss: 0.388087\n",
      "\n",
      "Test dataset:  Loss: 0.4090, Accuracy: 0.82, Precision: 0.60, Recall: 0.05, F1: 0.09, AUC: 0.75\n",
      "\n",
      "epoch: 8 [0/1000000 (0%)]\t training loss: 0.421808\n",
      "epoch: 8 [256000/1000000 (26%)]\t training loss: 0.423301\n",
      "epoch: 8 [512000/1000000 (51%)]\t training loss: 0.406586\n",
      "epoch: 8 [768000/1000000 (77%)]\t training loss: 0.388261\n",
      "\n",
      "Test dataset:  Loss: 0.4085, Accuracy: 0.82, Precision: 0.60, Recall: 0.05, F1: 0.10, AUC: 0.75\n",
      "\n",
      "epoch: 9 [0/1000000 (0%)]\t training loss: 0.421249\n",
      "epoch: 9 [256000/1000000 (26%)]\t training loss: 0.421451\n",
      "epoch: 9 [512000/1000000 (51%)]\t training loss: 0.404527\n",
      "epoch: 9 [768000/1000000 (77%)]\t training loss: 0.383374\n",
      "\n",
      "Test dataset:  Loss: 0.4081, Accuracy: 0.82, Precision: 0.61, Recall: 0.05, F1: 0.10, AUC: 0.75\n",
      "\n",
      "epoch: 10 [0/1000000 (0%)]\t training loss: 0.418260\n",
      "epoch: 10 [256000/1000000 (26%)]\t training loss: 0.422051\n",
      "epoch: 10 [512000/1000000 (51%)]\t training loss: 0.402937\n",
      "epoch: 10 [768000/1000000 (77%)]\t training loss: 0.386883\n",
      "\n",
      "Test dataset:  Loss: 0.4076, Accuracy: 0.82, Precision: 0.60, Recall: 0.06, F1: 0.10, AUC: 0.75\n",
      "\n",
      "epoch: 11 [0/1000000 (0%)]\t training loss: 0.419307\n",
      "epoch: 11 [256000/1000000 (26%)]\t training loss: 0.422130\n",
      "epoch: 11 [512000/1000000 (51%)]\t training loss: 0.402380\n",
      "epoch: 11 [768000/1000000 (77%)]\t training loss: 0.387069\n",
      "\n",
      "Test dataset:  Loss: 0.4074, Accuracy: 0.82, Precision: 0.60, Recall: 0.06, F1: 0.11, AUC: 0.75\n",
      "\n",
      "epoch: 12 [0/1000000 (0%)]\t training loss: 0.419419\n",
      "epoch: 12 [256000/1000000 (26%)]\t training loss: 0.416424\n",
      "epoch: 12 [512000/1000000 (51%)]\t training loss: 0.402601\n",
      "epoch: 12 [768000/1000000 (77%)]\t training loss: 0.386966\n",
      "\n",
      "Test dataset:  Loss: 0.4068, Accuracy: 0.82, Precision: 0.59, Recall: 0.06, F1: 0.11, AUC: 0.75\n",
      "\n",
      "epoch: 13 [0/1000000 (0%)]\t training loss: 0.417717\n",
      "epoch: 13 [256000/1000000 (26%)]\t training loss: 0.415641\n",
      "epoch: 13 [512000/1000000 (51%)]\t training loss: 0.405548\n",
      "epoch: 13 [768000/1000000 (77%)]\t training loss: 0.382679\n",
      "\n",
      "Test dataset:  Loss: 0.4065, Accuracy: 0.82, Precision: 0.59, Recall: 0.07, F1: 0.12, AUC: 0.75\n",
      "\n",
      "epoch: 14 [0/1000000 (0%)]\t training loss: 0.421189\n",
      "epoch: 14 [256000/1000000 (26%)]\t training loss: 0.415691\n",
      "epoch: 14 [512000/1000000 (51%)]\t training loss: 0.403889\n",
      "epoch: 14 [768000/1000000 (77%)]\t training loss: 0.382647\n",
      "\n",
      "Test dataset:  Loss: 0.4061, Accuracy: 0.82, Precision: 0.59, Recall: 0.07, F1: 0.13, AUC: 0.76\n",
      "\n",
      "epoch: 15 [0/1000000 (0%)]\t training loss: 0.418606\n",
      "epoch: 15 [256000/1000000 (26%)]\t training loss: 0.414464\n",
      "epoch: 15 [512000/1000000 (51%)]\t training loss: 0.404216\n",
      "epoch: 15 [768000/1000000 (77%)]\t training loss: 0.383190\n",
      "\n",
      "Test dataset:  Loss: 0.4061, Accuracy: 0.82, Precision: 0.57, Recall: 0.07, F1: 0.13, AUC: 0.76\n",
      "\n",
      "epoch: 16 [0/1000000 (0%)]\t training loss: 0.415849\n",
      "epoch: 16 [256000/1000000 (26%)]\t training loss: 0.407275\n",
      "epoch: 16 [512000/1000000 (51%)]\t training loss: 0.405497\n",
      "epoch: 16 [768000/1000000 (77%)]\t training loss: 0.384513\n",
      "\n",
      "Test dataset:  Loss: 0.4058, Accuracy: 0.82, Precision: 0.58, Recall: 0.07, F1: 0.13, AUC: 0.76\n",
      "\n",
      "epoch: 17 [0/1000000 (0%)]\t training loss: 0.416744\n",
      "epoch: 17 [256000/1000000 (26%)]\t training loss: 0.411270\n",
      "epoch: 17 [512000/1000000 (51%)]\t training loss: 0.401198\n",
      "epoch: 17 [768000/1000000 (77%)]\t training loss: 0.386059\n",
      "\n",
      "Test dataset:  Loss: 0.4056, Accuracy: 0.82, Precision: 0.58, Recall: 0.08, F1: 0.13, AUC: 0.76\n",
      "\n",
      "epoch: 18 [0/1000000 (0%)]\t training loss: 0.415271\n",
      "epoch: 18 [256000/1000000 (26%)]\t training loss: 0.407487\n",
      "epoch: 18 [512000/1000000 (51%)]\t training loss: 0.399883\n",
      "epoch: 18 [768000/1000000 (77%)]\t training loss: 0.385596\n",
      "\n",
      "Test dataset:  Loss: 0.4052, Accuracy: 0.82, Precision: 0.58, Recall: 0.08, F1: 0.14, AUC: 0.76\n",
      "\n",
      "epoch: 19 [0/1000000 (0%)]\t training loss: 0.415021\n",
      "epoch: 19 [256000/1000000 (26%)]\t training loss: 0.410686\n",
      "epoch: 19 [512000/1000000 (51%)]\t training loss: 0.401109\n",
      "epoch: 19 [768000/1000000 (77%)]\t training loss: 0.384174\n",
      "\n",
      "Test dataset:  Loss: 0.4050, Accuracy: 0.82, Precision: 0.58, Recall: 0.08, F1: 0.14, AUC: 0.76\n",
      "\n",
      "epoch: 20 [0/1000000 (0%)]\t training loss: 0.412000\n",
      "epoch: 20 [256000/1000000 (26%)]\t training loss: 0.409780\n",
      "epoch: 20 [512000/1000000 (51%)]\t training loss: 0.401545\n",
      "epoch: 20 [768000/1000000 (77%)]\t training loss: 0.386206\n",
      "\n",
      "Test dataset:  Loss: 0.4052, Accuracy: 0.82, Precision: 0.57, Recall: 0.08, F1: 0.14, AUC: 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_emb = BaseEmbeddingMLP(100, 16)\n",
    "optim = torch.optim.Adam(model_emb.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    train_embnet(model_emb, train_loader_emb, optim, epoch)\n",
    "    test_embnet(model_emb, valid_loader_emb)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a2394ed48906b449187dfe720e0119b9163ad54f60a6b36bd8129b90c9e9c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
