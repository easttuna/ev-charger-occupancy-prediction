{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import split_sequences, station_features, time_features\n",
    "from dataset import EvcDataset\n",
    "from basemodels import HistoricBase, RealtimeBase, MultiSeqBase, MultiSeqHybrid, MultiSeqUmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6624)\n"
     ]
    }
   ],
   "source": [
    "history = pd.read_csv('./data/input_table/history_by_station_pub.csv', parse_dates=['time'])\n",
    "station_attributes = pd.read_csv('./data/input_table/pubstation_feature_scaled.csv')\n",
    "station_embeddings = pd.read_csv('./data/input_table/pubstation_umap-embedding.csv')\n",
    "\n",
    "sid_encoder = {name:idx for idx, name in enumerate(station_embeddings.sid)}\n",
    "station_embeddings.sid = station_embeddings.sid.map(sid_encoder)\n",
    "station_attributes.sid = station_attributes.sid.map(sid_encoder)\n",
    "\n",
    "\n",
    "# transforms targer var. to binary indicator (1:high availabiltity, 0: low availability)\n",
    "data = history.set_index('time').mask(lambda x: x < 0.5,  1).mask(lambda x: x != 1, 0)\n",
    "data = data.T.reset_index().rename(columns={'index':'sid'})\n",
    "data.sid = data.sid.map(sid_encoder)\n",
    "\n",
    "data = data[data.sid.isin(station_attributes.sid)].set_index('sid')  # station feature가 있는 데이터로 한정\n",
    "data = data[data.mean(axis=1).le(0.9)]  # False 라벨이 10% 이상 존재하는 데이터 사용\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding = torch.tensor(station_embeddings.drop(columns=['sid']).values).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating inputs...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('generating inputs...')\n",
    "N_IN = 12\n",
    "N_OUT = 6\n",
    "N_HIST = 4\n",
    "\n",
    "n_stations = data.shape[0]\n",
    "n_windows = data.shape[1] - (N_OUT + 504*N_HIST)\n",
    "\n",
    "R_seq, H_seq, Y_seq = split_sequences(sequences=data.values, n_steps_in=N_IN, n_steps_out=N_OUT, n_history=N_HIST)\n",
    "T = time_features(time_idx=data.columns, n_steps_in=N_IN, n_steps_out=N_OUT, n_history=N_HIST, n_stations=n_stations)\n",
    "S = station_features(station_array=data.index, station_df=station_attributes, n_windows=n_windows) \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_seq = R_seq[:, :, np.newaxis]\n",
    "\n",
    "OUTPUT_IDX = 1\n",
    "H_seq = H_seq[:, OUTPUT_IDX, :, np.newaxis]\n",
    "T = T[:,OUTPUT_IDX,:]\n",
    "Y = Y_seq[:,OUTPUT_IDX, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345150, 12, 1) (345150, 4, 1) (345150, 1) (345150, 3) (345150, 16)\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(R_seq.shape, H_seq.shape, Y.shape, T.shape, S.shape)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split Train:Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset Size: 310635, Validset Size: 34515\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FRAC = 0.9\n",
    "n_train = int(data.shape[0] * TRAIN_FRAC * n_windows)\n",
    "\n",
    "trainset = EvcDataset(R_seq[:n_train,], H_seq[:n_train], T[:n_train,], S[:n_train,], Y[:n_train,])\n",
    "validset = EvcDataset(R_seq[n_train:,], H_seq[n_train:,], T[n_train:,], S[n_train:,], Y[n_train:,])\n",
    "print(f'Trainset Size: {len(trainset)}, Validset Size: {len(validset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with negative over sampling\n",
    "weights = np.where(trainset[:][-1].flatten() == 0., 5, 1)  # 5배\n",
    "num_samples = len(trainset)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None)\n",
    "train_loader = DataLoader(trainset, batch_size=32, sampler=sampler)\n",
    "\n",
    "# without sampling\n",
    "# train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(validset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "def train(model, train_dataloader, optim, epoch, verbose=0):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    for b_i, (R, H, T, S, y) in enumerate(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        pred = model(R, H, T, S)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if verbose:\n",
    "            if b_i % 3000 == 0:\n",
    "                print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                    epoch, b_i * len(R), len(train_dataloader.dataset),\n",
    "                    100 * b_i / len(train_dataloader), loss.item()\n",
    "                ))\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_total = torch.Tensor()\n",
    "        y_total = torch.Tensor()\n",
    "\n",
    "        for R, H, T, S, y in test_dataloader:\n",
    "            pred = model(R, H, T, S)\n",
    "            loss += criterion(pred, y).item()\n",
    "            pred_total = torch.cat((pred_total, pred.flatten()), dim=0)\n",
    "            y_total = torch.cat((y_total, y.flatten()), dim=0)\n",
    "\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    y_total = y_total.int().numpy()\n",
    "    pred_total = pred_total.numpy()\n",
    "    pred_label = np.where(pred_total > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "    recall = recall_score(y_total, pred_label)\n",
    "    precision = precision_score(y_total, pred_label)\n",
    "    f1 = f1_score(y_total, pred_label)\n",
    "    accuracy = accuracy_score(y_total, pred_label)\n",
    "    bal_accuracy = balanced_accuracy_score(y_total, pred_label)\n",
    "    auc = roc_auc_score(y_total, pred_total)\n",
    "\n",
    "    # print('Test dataset:  Loss: {:.4f}, Recall: {:.4f}, Precision: {:.4f}, F1: {:.4f}, Accuracy: {:.4f}, Balanced-Accuracy: {:.4f}, AUC: {:.4f}' \\\n",
    "    # .format(loss, recall, precision, f1, accuracy, bal_accuracy, auc))\n",
    "    print('Test dataset:  Loss: {:.4f}, Accuracy: {:.4f}, Balanced-Accuracy: {:.4f}, AUC: {:.4f}' \\\n",
    "    .format(loss, accuracy, bal_accuracy, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------HistoricBase-------\n",
      "<<Epoch 1>>\tTest dataset:  Loss: 0.2014, Accuracy: 0.5960, Balanced-Accuracy: 0.6327, AUC: 0.6852\n",
      "<<Epoch 2>>\tTest dataset:  Loss: 0.1976, Accuracy: 0.6142, Balanced-Accuracy: 0.6381, AUC: 0.6868\n",
      "<<Epoch 3>>\tTest dataset:  Loss: 0.2043, Accuracy: 0.6246, Balanced-Accuracy: 0.6340, AUC: 0.6875\n",
      "<<Epoch 4>>\tTest dataset:  Loss: 0.2016, Accuracy: 0.6201, Balanced-Accuracy: 0.6350, AUC: 0.6870\n",
      "<<Epoch 5>>\tTest dataset:  Loss: 0.2022, Accuracy: 0.5934, Balanced-Accuracy: 0.6373, AUC: 0.6862\n",
      "<<Epoch 6>>\tTest dataset:  Loss: 0.2070, Accuracy: 0.6110, Balanced-Accuracy: 0.6384, AUC: 0.6856\n",
      "<<Epoch 7>>\tTest dataset:  Loss: 0.2169, Accuracy: 0.5966, Balanced-Accuracy: 0.6414, AUC: 0.6883\n",
      "<<Epoch 8>>\tTest dataset:  Loss: 0.2115, Accuracy: 0.5965, Balanced-Accuracy: 0.6349, AUC: 0.6830\n",
      "<<Epoch 9>>\tTest dataset:  Loss: 0.2024, Accuracy: 0.6077, Balanced-Accuracy: 0.6358, AUC: 0.6856\n",
      "<<Epoch 10>>\tTest dataset:  Loss: 0.2071, Accuracy: 0.6091, Balanced-Accuracy: 0.6393, AUC: 0.6856\n",
      "-------RealtimeBase-------\n",
      "<<Epoch 1>>\tTest dataset:  Loss: 0.1633, Accuracy: 0.8016, Balanced-Accuracy: 0.6994, AUC: 0.7876\n",
      "<<Epoch 2>>\tTest dataset:  Loss: 0.1701, Accuracy: 0.7709, Balanced-Accuracy: 0.7020, AUC: 0.7885\n",
      "<<Epoch 3>>\tTest dataset:  Loss: 0.1543, Accuracy: 0.8115, Balanced-Accuracy: 0.6996, AUC: 0.7887\n",
      "<<Epoch 4>>\tTest dataset:  Loss: 0.1771, Accuracy: 0.7354, Balanced-Accuracy: 0.7044, AUC: 0.7893\n",
      "<<Epoch 5>>\tTest dataset:  Loss: 0.1568, Accuracy: 0.8146, Balanced-Accuracy: 0.6995, AUC: 0.7891\n",
      "<<Epoch 6>>\tTest dataset:  Loss: 0.1597, Accuracy: 0.8166, Balanced-Accuracy: 0.6978, AUC: 0.7889\n",
      "<<Epoch 7>>\tTest dataset:  Loss: 0.1599, Accuracy: 0.8203, Balanced-Accuracy: 0.6997, AUC: 0.7895\n",
      "<<Epoch 8>>\tTest dataset:  Loss: 0.1663, Accuracy: 0.7877, Balanced-Accuracy: 0.7018, AUC: 0.7902\n",
      "<<Epoch 9>>\tTest dataset:  Loss: 0.1716, Accuracy: 0.7767, Balanced-Accuracy: 0.7055, AUC: 0.7888\n",
      "<<Epoch 10>>\tTest dataset:  Loss: 0.1653, Accuracy: 0.7885, Balanced-Accuracy: 0.7047, AUC: 0.7888\n",
      "-------MultiSeqBase-------\n",
      "<<Epoch 1>>\tTest dataset:  Loss: 0.1773, Accuracy: 0.7596, Balanced-Accuracy: 0.7087, AUC: 0.7972\n",
      "<<Epoch 2>>\tTest dataset:  Loss: 0.1648, Accuracy: 0.8103, Balanced-Accuracy: 0.7034, AUC: 0.7962\n",
      "<<Epoch 3>>\tTest dataset:  Loss: 0.1637, Accuracy: 0.8071, Balanced-Accuracy: 0.7047, AUC: 0.7967\n",
      "<<Epoch 4>>\tTest dataset:  Loss: 0.1629, Accuracy: 0.7791, Balanced-Accuracy: 0.7081, AUC: 0.7975\n",
      "<<Epoch 5>>\tTest dataset:  Loss: 0.1642, Accuracy: 0.7855, Balanced-Accuracy: 0.7086, AUC: 0.7960\n",
      "<<Epoch 6>>\tTest dataset:  Loss: 0.1673, Accuracy: 0.7823, Balanced-Accuracy: 0.7080, AUC: 0.7975\n",
      "<<Epoch 7>>\tTest dataset:  Loss: 0.1599, Accuracy: 0.8078, Balanced-Accuracy: 0.7047, AUC: 0.7963\n",
      "<<Epoch 8>>\tTest dataset:  Loss: 0.1606, Accuracy: 0.7810, Balanced-Accuracy: 0.7069, AUC: 0.7962\n",
      "<<Epoch 9>>\tTest dataset:  Loss: 0.1594, Accuracy: 0.7903, Balanced-Accuracy: 0.7060, AUC: 0.7978\n",
      "<<Epoch 10>>\tTest dataset:  Loss: 0.1598, Accuracy: 0.7995, Balanced-Accuracy: 0.7036, AUC: 0.7967\n",
      "-------MultiSeqHybrid-------\n",
      "<<Epoch 1>>\tTest dataset:  Loss: 0.1630, Accuracy: 0.7703, Balanced-Accuracy: 0.7162, AUC: 0.8029\n",
      "<<Epoch 2>>\tTest dataset:  Loss: 0.1624, Accuracy: 0.7662, Balanced-Accuracy: 0.7209, AUC: 0.8051\n",
      "<<Epoch 3>>\tTest dataset:  Loss: 0.1683, Accuracy: 0.7488, Balanced-Accuracy: 0.7174, AUC: 0.8073\n",
      "<<Epoch 4>>\tTest dataset:  Loss: 0.1674, Accuracy: 0.7432, Balanced-Accuracy: 0.7165, AUC: 0.8050\n",
      "<<Epoch 5>>\tTest dataset:  Loss: 0.1654, Accuracy: 0.7388, Balanced-Accuracy: 0.7217, AUC: 0.8045\n",
      "<<Epoch 6>>\tTest dataset:  Loss: 0.1733, Accuracy: 0.7299, Balanced-Accuracy: 0.7107, AUC: 0.7997\n",
      "<<Epoch 7>>\tTest dataset:  Loss: 0.1619, Accuracy: 0.7508, Balanced-Accuracy: 0.7136, AUC: 0.7990\n",
      "<<Epoch 8>>\tTest dataset:  Loss: 0.1615, Accuracy: 0.7532, Balanced-Accuracy: 0.7137, AUC: 0.7998\n",
      "<<Epoch 9>>\tTest dataset:  Loss: 0.1654, Accuracy: 0.7355, Balanced-Accuracy: 0.7093, AUC: 0.7899\n",
      "<<Epoch 10>>\tTest dataset:  Loss: 0.1637, Accuracy: 0.7323, Balanced-Accuracy: 0.7136, AUC: 0.7958\n",
      "-------MultiSeqUmap-------\n",
      "<<Epoch 1>>\tTest dataset:  Loss: 0.1552, Accuracy: 0.8013, Balanced-Accuracy: 0.7114, AUC: 0.8026\n",
      "<<Epoch 2>>\tTest dataset:  Loss: 0.1628, Accuracy: 0.7917, Balanced-Accuracy: 0.7127, AUC: 0.8053\n",
      "<<Epoch 3>>\tTest dataset:  Loss: 0.1585, Accuracy: 0.7848, Balanced-Accuracy: 0.7166, AUC: 0.8049\n",
      "<<Epoch 4>>\tTest dataset:  Loss: 0.1545, Accuracy: 0.8008, Balanced-Accuracy: 0.7147, AUC: 0.8058\n",
      "<<Epoch 5>>\tTest dataset:  Loss: 0.1529, Accuracy: 0.8107, Balanced-Accuracy: 0.7124, AUC: 0.8071\n",
      "<<Epoch 6>>\tTest dataset:  Loss: 0.1444, Accuracy: 0.8212, Balanced-Accuracy: 0.7112, AUC: 0.8062\n",
      "<<Epoch 7>>\t"
     ]
    }
   ],
   "source": [
    "models = {'HistoricBase':HistoricBase, 'RealtimeBase':RealtimeBase, 'MultiSeqBase':MultiSeqBase, 'MultiSeqHybrid':MultiSeqHybrid, 'MultiSeqUmap':MultiSeqUmap}\n",
    "for name, basemodel in models.items():\n",
    "    print(f'-------{name}-------')\n",
    "    if name == 'MultiSeqUmap':\n",
    "        model = basemodel(hidden_size=16, embedding_dim=8, pretrained_embedding=umap_embedding)\n",
    "    else:\n",
    "        model = basemodel(hidden_size=16, embedding_dim=8)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    N_EPOCH = 10\n",
    "    for epoch in range(1,N_EPOCH+1):\n",
    "        print(f'<<Epoch {epoch}>>', end='\\t')\n",
    "        train(model, train_loader, optim, epoch, verbose=0)\n",
    "        test(model, valid_loader)\n",
    "\n",
    "    # y_true = sample_data[4].flatten().detach().numpy()\n",
    "    # y_pred = model(*sample_data[:4]).flatten().detach().numpy()\n",
    "    # y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(40,8))\n",
    "    # ax.plot(y_true, color='g')\n",
    "    # ax.plot(y_pred, color='r')\n",
    "    # plt.savefig(f'./images/{name}_out-{OUTPUT_IDX}_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a2394ed48906b449187dfe720e0119b9163ad54f60a6b36bd8129b90c9e9c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
